{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJpfZ68GDWbs"
      },
      "source": [
        "### Praktikum 2"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "vscode": {
          "languageId": "plaintext"
        },
        "id": "ew94jjMpDWbu"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf # digunakan untuk membangun dan melatih model machine learning\n",
        "import numpy as np # digunakan untuk menangani array multidimensi dan operasi matematis\n",
        "import os # digunakan untuk berinteraksi dengan sistem operasi\n",
        "import time # digunakan untuk mengukur waktu"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt') # mengunduh file dari URL"
      ],
      "metadata": {
        "id": "FIVGfCGzDiO8"
      },
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Read, then decode for py2 compat.\n",
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8') # digunakan untuk membaca file teks yang dikodekan dalam UTF-8 dan mengembalikan konten file tersebut sebagai string\n",
        "# length of text is the number of characters in it\n",
        "print(f'Length of text: {len(text)} characters') # mencetak panjang dari string text"
      ],
      "metadata": {
        "id": "AQImVs1TDvlm",
        "outputId": "6a4db1c8-ac3e-4aa8-db48-a1cbd6c7a10e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250]) # Menampilkan 250 karakter pertama"
      ],
      "metadata": {
        "id": "Dt0phpIkDyJO",
        "outputId": "54f9938f-05bf-4742-d5a9-a96dc8d9de49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text)) # membuat vocab dengan set dari teks yang diurutkan\n",
        "print(f'{len(vocab)} unique characters') # menampilkan panjang variabel vocab"
      ],
      "metadata": {
        "id": "SC3JsfLCD4SY",
        "outputId": "f61b695f-7f69-4d03-b137-d31dd71f593b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Mengolah Teks"
      ],
      "metadata": {
        "id": "EA9xTlpIEFWk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz'] # Membuat list example_texts\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8') # memecah teks yang diberikan menjadi urutan poin kode Unicode\n",
        "chars # menampilkan variabel chars"
      ],
      "metadata": {
        "id": "fJ4fiY18D78k",
        "outputId": "d7f065b7-46ec-4d3d-8273-b4bd1d305efa",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None) # membuat lapisan StringLookup TensorFlow yang dapat digunakan untuk mengkonversi token teks menjadi ID numerik"
      ],
      "metadata": {
        "id": "ovcn2DQIETp3"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars) # mengkonversi urutan poin kode Unicode chars menjadi urutan ID numerik menggunakan lapisan StringLookup\n",
        "ids # Menampilkan variabel ids"
      ],
      "metadata": {
        "id": "cSlIg26HEcUk",
        "outputId": "dec494fd-91ef-4a59-be13-acb00e6c4801",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None) # membuat lapisan StringLookup TensorFlow dengan tambahan argument invert=True dan tidak menggunakan token mask"
      ],
      "metadata": {
        "id": "R6mSD0ttEd5x"
      },
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids) # mengkonversi urutan poin kode Unicode chars menjadi urutan ID numerik menggunakan lapisan StringLookup\n",
        "chars # Menampilkan variabel ids"
      ],
      "metadata": {
        "id": "mfyiJ6Q3Ejhg",
        "outputId": "cb44114d-de16-4044-f92d-a7b8aea20fc0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy() # menggabungkan nilai pada chars menjadi string"
      ],
      "metadata": {
        "id": "gvcLtFIpFF00",
        "outputId": "c8b7efad-d1c8-460f-83ab-e714a4e9eded",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1) # mengembalikan string yang digabungkan dari semua token teks dalam urutan ID numerik ids"
      ],
      "metadata": {
        "id": "QmtiXCQeFKJX"
      },
      "execution_count": 44,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Prediksi - Membuat Training Set dan Target"
      ],
      "metadata": {
        "id": "Mmv5gwEmFZsy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8')) # mengkonversi semua karakter dalam teks text menjadi ID numerik menggunakan lapisan StringLookup ids_from_chars\n",
        "all_ids # Menampilkan variabel"
      ],
      "metadata": {
        "id": "Mr4jb4mQFN1S",
        "outputId": "341297bc-0668-4ad2-9c7d-eccd179ec583",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids) # membuat dataset TensorFlow dari urutan ID numerik all_ids"
      ],
      "metadata": {
        "id": "ej6Yft44Frc1"
      },
      "execution_count": 46,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10): # Melakukan perulangan pada 10 elemen pertama\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8')) #  mencetak token teks yang sesuai dengan ID numerik ids"
      ],
      "metadata": {
        "id": "7XPSzv50FwkZ",
        "outputId": "e7de1d24-e8a7-4315-b7b4-148d9e94f52f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100 # Inisialisasi variabel seq_length"
      ],
      "metadata": {
        "id": "b_snwdGpF7xb"
      },
      "execution_count": 48,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True) # membuat batch tensor ID numerik dari dataset ids_dataset, dengan ID urutan selanjutnya sebagai target dan mengabaikan batch terakhir jika panjangnya kurang dari seq_length+1\n",
        "\n",
        "for seq in sequences.take(1): # Melakukan perulangan nilai pertama\n",
        "  print(chars_from_ids(seq)) # mencetak token teks yang sesuai dengan urutan ID"
      ],
      "metadata": {
        "id": "Xkz1tj77F-0S",
        "outputId": "f3ee1a60-b559-4a1a-e989-574ad2ec9e2e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5): # Melakukan perulangan pada 5 elemen pertama\n",
        "    print(text_from_ids(seq).numpy()) # mencetak teks yang sesuai dengan urutan ID numerik seq"
      ],
      "metadata": {
        "id": "gdkDSJ-BGCLc",
        "outputId": "19e27289-a90f-400a-f11e-0911e32b6265",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1] # mengambil seluruh nilai kecuali nilai terakhir\n",
        "    target_text = sequence[1:] # mengambil seluruh nilai kecuali nilai pertama\n",
        "    return input_text, target_text # mengembalikan variabel input_text dan target_text"
      ],
      "metadata": {
        "id": "2XEBMjkFGmAM"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\")) # menjalankan function split_input_target dengan argument list 'Tensorflow'"
      ],
      "metadata": {
        "id": "3MJ9Ma4XGp4r",
        "outputId": "a7cadccb-5c15-45c7-d116-c482387ccc49",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target) # memetakan setiap elemen dalam dataset sequences ke urutan ID numerik yang berisi input teks dan target teks"
      ],
      "metadata": {
        "id": "ccbF7XwNHcfk"
      },
      "execution_count": 53,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1): # melakukan perulangan pada elemen pertama dataset dan membaginya ke variabel input_example dan target_example\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy()) # menampilkan nilai input_example\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy()) # menampilkan nilai target_example"
      ],
      "metadata": {
        "id": "vQBN2kvwHfz-",
        "outputId": "87fae1e0-078a-496d-8188-598758ccc4a0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Bath Training"
      ],
      "metadata": {
        "id": "XdDiGTXqHn0X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Batch size\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000 # Inisialisasi variabel BUFFER_SIZE\n",
        "\n",
        "dataset = (\n",
        "    dataset # Membuat dataset\n",
        "    .shuffle(BUFFER_SIZE) # mengacak urutan elemen dalam dataset dan menyimpan elemen-elemen yang diacak berdasarkan buffer_size\n",
        "    .batch(BATCH_SIZE, drop_remainder=True) # mengelompokkan elemen-elemen dalam dataset menjadi batch dan  elemen-elemen yang tidak dapat dibagi oleh BATCH_SIZE akan dibuang\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE)) # TensorFlow secara otomatis menentukan ukuran buffer yang optimal untuk prefetch\n",
        "\n",
        "dataset # menampilkan variabel dataset"
      ],
      "metadata": {
        "id": "Szmpz7pcHrbD",
        "outputId": "84ea05d1-57c4-45dc-91c8-4a9292f1361b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Membuat Model"
      ],
      "metadata": {
        "id": "vwlnesjzH6NK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(ids_from_chars.get_vocabulary()) # menghitung ukuran vocabulary dari lapisan StringLookup ids_from_chars\n",
        "\n",
        "embedding_dim = 256 # Inisialisasi variabel embedding_dim\n",
        "\n",
        "rnn_units = 1024 # Inisialisasi variabel rnn_units"
      ],
      "metadata": {
        "id": "eoenckkzH1QZ"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim) # membuat embedding layer untuk memproses urutan ID numerik yang dihasilkan oleh lapisan StringLookup\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units, # Jumlah unit sebanyak rnn_units\n",
        "                                   return_sequences=True, # mengembalikan urutan vektor numerik yang sama dengan panjang urutan input\n",
        "                                   return_state=True) # membuat lapisan GRU untuk memproses urutan vektor numerik yang dihasilkan oleh lapisan embedding dan mengembalikan keadaan internal dari lapisan GRU\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size) # membuat layer dense dengan argument vacab_size\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs # menyimpan variabel inputs ke dalam variabel x\n",
        "    x = self.embedding(x, training=training) # memproses urutan ID numerik x menggunakan lapisan embedding self.embedding dengan set mode training berdasarkan variabel training\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x) # mendapatkan keadaan awal dari lapisan GRU\n",
        "    x, states = self.gru(x, initial_state=states, training=training) # memproses urutan vektor numerik x menggunakan lapisan GRU self.gru dengan keadaan awal states dan mode berdasarkan variabel training\n",
        "    x = self.dense(x, training=training) # memproses urutan vektor numerik x menggunakan lapisan dense\n",
        "\n",
        "    if return_state:\n",
        "      return x, states # mengembalikan nilai x dan states\n",
        "    else:\n",
        "      return x # mengembalikan nilai x"
      ],
      "metadata": {
        "id": "NSbkZ_HxICbM"
      },
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel( # Memanggil function MyModel()\n",
        "    vocab_size=vocab_size, # menambahkan argument berupa variabel vocab_size\n",
        "    embedding_dim=embedding_dim, # menambahkan argument berupa variabel embedding_dim\n",
        "    rnn_units=rnn_units) # menambahkan argument berupa variabel rnn_units"
      ],
      "metadata": {
        "id": "q6HJXEJWINEQ"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menguji Model"
      ],
      "metadata": {
        "id": "-preD-iQIXDq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1): # Melakukan perulangan dengan elemen pertama yang dibagi dalam variabel input_example_batch dan target_example_batch\n",
        "    example_batch_predictions = model(input_example_batch) # menghasilkan prediksi untuk batch input input_example_batch menggunakan model\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\") # menampilkan ukuran example_batch_predictions"
      ],
      "metadata": {
        "id": "sBUEhjlcIUAE",
        "outputId": "00d4d514-c353-4f0e-dae1-119d6e8efb2c",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary() # mencetak ringkasan dari model machine learning yang telah dibuat"
      ],
      "metadata": {
        "id": "UftZE77HIcOk",
        "outputId": "531787be-ff8c-4940-a18e-60ad44278963",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_2 (Embedding)     multiple                  16896     \n",
            "                                                                 \n",
            " gru_2 (GRU)                 multiple                  3938304   \n",
            "                                                                 \n",
            " dense_2 (Dense)             multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1) # mengambil sampel dari distribusi kategorikal yang ditentukan oleh vektor probabilitas example_batch_predictions[0] dengan jumlah sampel yang diambil adalah 1\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy() # menghapus dimensi dari tensor dan mengubah tensor sampled_indices menjadi array NumPy"
      ],
      "metadata": {
        "id": "9SY0-noqI8We"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices # menampilkan array variabel sampled_indices"
      ],
      "metadata": {
        "id": "o5aaEjM0I_Fl",
        "outputId": "a725ffc0-ba47-47b5-8fe3-0ba9046afac5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([24, 45,  0, 26, 55, 54, 42, 49,  3, 55, 49, 60,  1, 44, 63, 47, 54,\n",
              "       22, 25, 43, 10,  2, 64, 23, 13, 52, 42, 14, 41, 64,  2, 46, 55,  4,\n",
              "       30, 60, 14, 46, 20, 49, 65, 26, 54, 13, 61, 49, 22, 15, 13, 34, 35,\n",
              "       35, 47, 15, 39, 22, 47, 27, 43, 19, 23,  6, 44, 60, 17, 50, 60, 37,\n",
              "       43,  8,  2, 30, 14, 27, 55, 39, 10, 62, 39, 12, 61, 23, 53, 60, 53,\n",
              "        5, 11, 43, 21,  9,  6, 13, 62, 22, 17, 57,  8, 26, 56, 30])"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy()) # mencetak input pertama dalam batch input_example_batch\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy()) # mencetak prediksi karakter berikutnya untuk input pertama dalam batch input_example_batch"
      ],
      "metadata": {
        "id": "v_hueHXwJCHX",
        "outputId": "89cc40d2-3db9-4fc7-efc3-e1270abda7ef",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 63,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b't banish reason\\nFor inequality; but let your reason serve\\nTo make the truth appear where it seems hi'\n",
            "\n",
            "Next Char Predictions:\n",
            " b\"Kf[UNK]Mpocj!pju\\nexhoILd3 yJ?mcAby gp$QuAgGjzMo?vjIB?UVVhBZIhNdFJ'euDkuXd- QANpZ3wZ;vJnun&:dH.'?wIDr-MqQ\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Train Model"
      ],
      "metadata": {
        "id": "2fAfo3kOJOeW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True) # membuat fungsi kerugian Sparse Categorical Crossentropy dengan menerima logits sebagai input"
      ],
      "metadata": {
        "id": "I_brDdASJG3_"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions) # menghitung rata-rata kerugian untuk batch input example_batch_predictions\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\") # menampilkan ukuran example_batch_predictions\n",
        "print(\"Mean loss:        \", example_batch_mean_loss) # menampilkan mean loss"
      ],
      "metadata": {
        "id": "anbaprB0KL4J",
        "outputId": "beff5e8c-0b01-4a13-89ac-d1331e00d7ec",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1892314, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy() # menghitung eksponen dari rata-rata kerugian untuk batch input"
      ],
      "metadata": {
        "id": "hSkqOPfQKPcA",
        "outputId": "d3030fe1-573b-45dc-d1eb-c43ce5119676",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "65.97207"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss) # Compile model denga optimizer ADAM dan argument variabel loss"
      ],
      "metadata": {
        "id": "6c5gzWw7KSKb"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Konfigurasi Checkpoint"
      ],
      "metadata": {
        "id": "hd8R0IweKVB3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints' # membuat direktori untuk menyimpan checkpoint model\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\") # membuat prefix nama file untuk checkpoint model\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True) # menyimpan checkpoint model machine learning ke direktori checkpoint_dir dengan prefix nama file ckpt_{epoch} dan yang disimpan hanya berupa bobotnya\n",
        ""
      ],
      "metadata": {
        "id": "599zQJpoKX3Q"
      },
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Melakukan Proses Training"
      ],
      "metadata": {
        "id": "ufQQix2FKgx-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20 # Inisialisasi variabel EPOCHS\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback]) # melatih model  dengan dataset dataset selama sebanyak EPOCHS, dengan menggunakan callback untuk menyimpan checkpoint model"
      ],
      "metadata": {
        "id": "EckbEUBnKegi",
        "outputId": "7dbbbb20-9994-45cf-ee6d-f342b6d257d7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 15s 51ms/step - loss: 2.7140\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 11s 51ms/step - loss: 1.9813\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 10s 50ms/step - loss: 1.7065\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.5477\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 11s 51ms/step - loss: 1.4484\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.3803\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 10s 51ms/step - loss: 1.3283\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.2827\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 12s 52ms/step - loss: 1.2423\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 1.2029\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.1623\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.1219\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 1.0778\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 10s 52ms/step - loss: 1.0332\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 0.9842\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 11s 53ms/step - loss: 0.9342\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 0.8815\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 0.8272\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 11s 52ms/step - loss: 0.7764\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 10s 52ms/step - loss: 0.7274\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generate Teks"
      ],
      "metadata": {
        "id": "fJqdQTQ1L-fg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class OneStep(tf.keras.Model):\n",
        "  def __init__(self, model, chars_from_ids, ids_from_chars, temperature=1.0):\n",
        "    super().__init__()\n",
        "    self.temperature = temperature\n",
        "    self.model = model\n",
        "    self.chars_from_ids = chars_from_ids\n",
        "    self.ids_from_chars = ids_from_chars\n",
        "\n",
        "    # Create a mask to prevent \"[UNK]\" from being generated.\n",
        "    skip_ids = self.ids_from_chars(['[UNK]'])[:, None]\n",
        "    sparse_mask = tf.SparseTensor(\n",
        "        # Put a -inf at each bad index.\n",
        "        values=[-float('inf')]*len(skip_ids),\n",
        "        indices=skip_ids,\n",
        "        # Match the shape to the vocabulary\n",
        "        dense_shape=[len(ids_from_chars.get_vocabulary())])\n",
        "    self.prediction_mask = tf.sparse.to_dense(sparse_mask)\n",
        "\n",
        "  @tf.function\n",
        "  def generate_one_step(self, inputs, states=None):\n",
        "    # Convert strings to token IDs.\n",
        "    input_chars = tf.strings.unicode_split(inputs, 'UTF-8')\n",
        "    input_ids = self.ids_from_chars(input_chars).to_tensor()\n",
        "\n",
        "    # Run the model.\n",
        "    # predicted_logits.shape is [batch, char, next_char_logits]\n",
        "    predicted_logits, states = self.model(inputs=input_ids, states=states,\n",
        "                                          return_state=True)\n",
        "    # Only use the last prediction.\n",
        "    predicted_logits = predicted_logits[:, -1, :]\n",
        "    predicted_logits = predicted_logits/self.temperature\n",
        "    # Apply the prediction mask: prevent \"[UNK]\" from being generated.\n",
        "    predicted_logits = predicted_logits + self.prediction_mask\n",
        "\n",
        "    # Sample the output logits to generate token IDs.\n",
        "    predicted_ids = tf.random.categorical(predicted_logits, num_samples=1)\n",
        "    predicted_ids = tf.squeeze(predicted_ids, axis=-1)\n",
        "\n",
        "    # Convert from token ids to characters\n",
        "    predicted_chars = self.chars_from_ids(predicted_ids)\n",
        "\n",
        "    # Return the characters and model state.\n",
        "    return predicted_chars, states"
      ],
      "metadata": {
        "id": "KkpQb-dQL8Ss"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "one_step_model = OneStep(model, chars_from_ids, ids_from_chars) # membuat model one-step untuk menghasilkan teks"
      ],
      "metadata": {
        "id": "i4k8-4XLM5s3"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time() # mencatat waktu mulai dari suatu proses\n",
        "states = None # Memberikan nilai awal None pada states\n",
        "next_char = tf.constant(['ROMEO:']) # membuat tensor konstan yang berisi karakter ROMEO, yang nilainya tidak dapat diubah\n",
        "result = [next_char] # membuat list yang berisi tensor konstan\n",
        "\n",
        "for n in range(1000): # Melakukan 1000 perulangan\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states) # menghasilkan karakter berikutnya dari input teks menggunakan model one-step one_step_model\n",
        "  result.append(next_char) # Menambahkan nilai next_char ke list result\n",
        "\n",
        "result = tf.strings.join(result) # menggabungkan semua elemen dari list result menjadi satu string.\n",
        "end = time.time() # mencatat waktu proses berakhir\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80) # mencetak teks yang dihasilkan oleh model one-step, diikuti oleh garis bawah sepanjang 80 karakter dalam format decode utf-8\n",
        "print('\\nRun time:', end - start) # Menampilkan waktu runtime dari selisih waktu mulai dan selesai"
      ],
      "metadata": {
        "id": "4jUbCE4oM9PZ",
        "outputId": "3f60332b-5baf-4f27-db7f-586f5d9fb94f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "Then most never o'erwear him to her life?\n",
            "\n",
            "JULIET:\n",
            "To let it is for policy.\n",
            "\n",
            "FLORIZEL:\n",
            "I needs must go till.\n",
            "\n",
            "A Fige. But, O, he'l oft,\n",
            "And hath a harm in't then comes shake it.\n",
            "\n",
            "LUCENTIO:\n",
            "And what good morning without bears more tears.\n",
            "\n",
            "LADY GREY:\n",
            "Methinks I would I were i' the laughtain wears;\n",
            "Go, bill, a crow, both honour now in peace:\n",
            "Beseech you, so your free contents go you in such a righter bed.\n",
            "\n",
            "First Murderer:\n",
            "Thou hadst an body should be that so set door.\n",
            "3 KING HENRY VI\n",
            "\n",
            "WARDINA:\n",
            "How! nurse?\n",
            "\n",
            "Second Senator:\n",
            "He cannot: we\n",
            "Will have them yet.\n",
            "Ah, what a sceptre's heir\n",
            "Of lambs praised their hell, as brought\n",
            "To this so-noise-mour's wife in hand: so, take my revenge\n",
            "Are all frants for joy or to this mass, Good, Sir boistero\n",
            "As far as many fears time thus hard-teaching nature,\n",
            "Unlikely longes to encounter? his channing\n",
            "may catching.\n",
            "\n",
            "ROMEO:\n",
            "Thou wilt amend thy brain; And now I care\n",
            "not right what raised the happy evil intent:\n",
            "Acquaint the king in Padua for any\n",
            "often I with an u \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 5.45184588432312\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "start = time.time() # mencatat waktu mulai dari suatu proses\n",
        "states = None # Memberikan nilai awal None pada states\n",
        "next_char = tf.constant(['ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:', 'ROMEO:']) # membuat tensor konstan yang berisi lima karakter ROMEO, yang nilainya tidak dapat diubah\n",
        "result = [next_char] # membuat list yang berisi tensor konstan\n",
        "\n",
        "for n in range(1000): # Melakukan 1000 perulangan\n",
        "  next_char, states = one_step_model.generate_one_step(next_char, states=states) # menghasilkan karakter berikutnya dari input teks menggunakan model one-step one_step_model\n",
        "  result.append(next_char) # Menambahkan nilai next_char ke list result\n",
        "\n",
        "result = tf.strings.join(result) # menggabungkan semua elemen dari list result menjadi satu string.\n",
        "end = time.time() # mencatat waktu proses berakhir\n",
        "print(result, '\\n\\n' + '_'*80) # mencetak teks yang dihasilkan oleh model one-step, diikuti oleh garis bawah sepanjang 80 karakter\n",
        "print(result[0].numpy().decode('utf-8'), '\\n\\n' + '_'*80) # mencetak teks yang dihasilkan oleh model one-step, diikuti oleh garis bawah sepanjang 80 karakter  dalam format decode utf-8\n",
        "print('\\nRun time:', end - start) # Menampilkan waktu runtime dari selisih waktu mulai dan selesai"
      ],
      "metadata": {
        "id": "PDhgf7XnNNsm",
        "outputId": "d81123e0-8524-4380-a1d2-278c303e7268",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 74,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b\"ROMEO:\\nFair lips, a doble confine at my back,\\nThat are being begs at my request;\\nAnd I, whomas I have senter'd there were\\nwindows tatch over Clarence, we will dost thou nother.\\n\\nGLOUCESTER:\\nThou dost take no conceality, and bear himself\\nAs honourable lord chamberlalo!\\n\\nDORSET:\\nMy lenJamenta's boty subjects now.\\nMy lord lessed was, he bear me: in paunt a troubly\\nYou have frown'd upon my heart that late.\\n\\nMENENIUS:\\nI was not my good lord; since that gleat'st not this feat?\\nOur hope more, fair Bopierey.' 'Now you, catched, great;\\nThe boar will revenge upon you are all born,\\nBeside your wisdoms, my father, if thou wast\\nAs sorry the earthly gatherous sound;\\nAnd, every sleep and executioner, so took of him\\nA dismal throat, shall we to A woman's tear?\\n\\nTuts,\\nLet me do soe! thy father is amorout,\\nHere will day in his head: the senate power's\\nBunkind-like replord; soon am I ne'er advertised\\nThat, good feeble and for require;\\nAnd at that clife, and that in very stroke\\nTo likely unsever'd in his root,\\n\"\n",
            " b\"ROMEO:\\nGentlemen: my lord!\\n\\nKING RICHARD II:\\nO, 'tis the hum is one redeeming else\\nBut only that last by tears. And to bear me\\nThe devil the Adgul Sun so grossly, as I am, nor\\nthat I am.\\n\\nSOMERSET:\\nThe horses' ready belong this delight her royal,\\nThe excupio can again about\\nMy bounty, alway, so dissivides.\\n\\nSTANLEY:\\nMy lord, will be her father;\\nYea, lords, fetch together, hear me but\\nA very little about inconstance, who,\\nare at their readiness to come and repent.\\n\\nROMEO:\\nThis is the queen's name speak three presence;\\nFor, son: were here follow: thou dost endurbed, it\\ntaught you or yours, and the refule of him.\\n\\nMENENIUS:\\nI am good father's hounds: before an hour should we\\nWould hold out for the master of the world,\\nBy God, thy eye's toporrow shall not be\\nThe Roman and thy statue own cap,\\nAnd that the very bone wail the hours\\nAnd yet bired these freety helps,\\nOf their own penitence and the very disturber,\\nOr with this new done, the measure must be\\nTred our commands to be maid or slowly; not l\"\n",
            " b\"ROMEO:\\nThe shepherd, so it is, the father willingly robes!\\n\\nGLOUCESTER:\\n\\nKING RICHARD II:\\nIf ever froward England therefore, like a could kill,\\nThen marchased he for his alike has it intent\\nThat Plantagenet. I must be new character.\\nMine I am not too much my mother and\\nBy heaven, thou wast not love to Angelo.\\n\\nTYBALT:\\nBold grace, Poil Ty: not for its: to the spirit.\\nWhich sigs for both, and Juliet in the haughty heart;\\nThe full, of the beastly come of tears.\\n\\nLEONTES:\\nWhy, how names,\\nWe must consider, every intent of grief.\\n\\nYORK:\\nCry, our part, and he told me, my gracious lord!\\n\\nJULIET:\\nBut teach them to our accusation, a\\ndream out what I have stoly begraw with\\nmarriage; our pawns but ansience he will down.\\n\\nSecond Murderer:\\nWho told me how that he is heard of thyself?\\nLet nite unto your either passing was together.\\n\\nKATHARINA:\\nJone him, and all occasion of some country.\\n\\nFirst Senator:\\nWho, added offence, be guardulated.\\n\\nANTONIO:\\nWhy, therefore let't in tumorous in:\\nBut ere I may war as t\"\n",
            " b\"ROMEO:\\nThe Sunnot Posiders, to wait upon the privide;\\nEither fearful, which she hate to remors,\\nThe wisdom will sceptor, wright by this became\\nLeft betwitts his majesty'd?\\n\\nKATHARINA:\\nChange him now,\\nI have found such pity fool, wouldster under this\\nThat art their horses enceed I am resolve:\\nI'll be our monadions. Adieu, and all\\nrestrain'd heaviest love. There's no delighted sand\\nThese words that made thy battle pray.\\n\\nLADY ANNE:\\nYou not Juliet light, you bid good morrow or no:\\nBe married. The urging of the world will be\\nhadged, or my father, sir. I'll keep till now.\\n\\nEDWARD:\\nO Helmemos, Christial be four ears:\\nThere is a word in 'tis within: the other seens\\nThe eye of heaven hath enter our heart!\\n\\nLARTIUS:\\nObility\\nTake on a subject star it: 't be thy fine\\nThat thou dost love a lover bend:\\nTherefore 'tis my good father, Grey, rew'st and rest!\\nForgiveness, my brother Bipare's chamber\\nTo one hall make a thurn of second and dise:\\nHungs by the very day ready and undert\\nUntermand to crave, and we\"\n",
            " b\"ROMEO:\\nHe thinks a subject acceptance, since it\\nis but a gentler with a limbth; be\\nshall I convey not to come to fight:\\nAll going to you, sir, as many morning instants\\nOf bow shall bring for news of her own such a fool.\\nHath a wild heart were all senses of\\nthe world; and therefore came from Rome\\nThen say to have her mother; what occuse's other,\\nTheir country with his good adieut;\\nOne who is companyin to do thee blade\\nOf never brook where he widows: hence his matter,\\nThe more heard it. My quieen on earth.\\n\\nPRINCE EDWARD:\\nSay that this true years early in this peech?\\nFor chamity, bear him what he will purpose\\nUnto the kingdom aferely youth;\\ntherefore thy old grain or two infect off by words\\nAnd pluck dilegnable and all my visitation in that.\\n\\nBoth:\\nO, he's a dream ten me; let her should hear me speak.\\n\\nDUKE VINCENTIO:\\nYour own daughter's off; no title princes can defend\\nThe cause to you: if my feed uncles and hell!\\nThe heavens go belongill'd in blood to thee,\\nThan that he would forget thee,\\nOf\"], shape=(5,), dtype=string) \n",
            "\n",
            "________________________________________________________________________________\n",
            "ROMEO:\n",
            "Fair lips, a doble confine at my back,\n",
            "That are being begs at my request;\n",
            "And I, whomas I have senter'd there were\n",
            "windows tatch over Clarence, we will dost thou nother.\n",
            "\n",
            "GLOUCESTER:\n",
            "Thou dost take no conceality, and bear himself\n",
            "As honourable lord chamberlalo!\n",
            "\n",
            "DORSET:\n",
            "My lenJamenta's boty subjects now.\n",
            "My lord lessed was, he bear me: in paunt a troubly\n",
            "You have frown'd upon my heart that late.\n",
            "\n",
            "MENENIUS:\n",
            "I was not my good lord; since that gleat'st not this feat?\n",
            "Our hope more, fair Bopierey.' 'Now you, catched, great;\n",
            "The boar will revenge upon you are all born,\n",
            "Beside your wisdoms, my father, if thou wast\n",
            "As sorry the earthly gatherous sound;\n",
            "And, every sleep and executioner, so took of him\n",
            "A dismal throat, shall we to A woman's tear?\n",
            "\n",
            "Tuts,\n",
            "Let me do soe! thy father is amorout,\n",
            "Here will day in his head: the senate power's\n",
            "Bunkind-like replord; soon am I ne'er advertised\n",
            "That, good feeble and for require;\n",
            "And at that clife, and that in very stroke\n",
            "To likely unsever'd in his root,\n",
            " \n",
            "\n",
            "________________________________________________________________________________\n",
            "\n",
            "Run time: 3.3097150325775146\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Ekspor Model Generator"
      ],
      "metadata": {
        "id": "AxKO1vACNd_P"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tf.saved_model.save(one_step_model, 'one_step') # menyimpan model one-step one_step_model ke direktori one_step\n",
        "one_step_reloaded = tf.saved_model.load('one_step') # memuat model one-step yang disimpan di direktori one_step ke dalam variabel one_step_reloaded"
      ],
      "metadata": {
        "id": "BRSDIWVtNa8D",
        "outputId": "e274a81c-30de-4d71-dcef-995d825aebe4",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:Skipping full serialization of Keras layer <__main__.OneStep object at 0x7893c8167cd0>, because it is not built.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n",
            "WARNING:tensorflow:Model's `__init__()` arguments contain non-serializable objects. Please implement a `get_config()` method in the subclassed Model for proper saving and loading. Defaulting to empty config.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "states = None # Memberikan nilai awal None pada states\n",
        "next_char = tf.constant(['ROMEO:']) # membuat tensor konstan yang berisi karakter ROMEO, yang nilainya tidak dapat diubah\n",
        "result = [next_char] # membuat list yang berisi tensor konstan\n",
        "\n",
        "for n in range(100): # Melakukan 100 perulangan\n",
        "  next_char, states = one_step_reloaded.generate_one_step(next_char, states=states) # menghasilkan karakter berikutnya dari input teks menggunakan model one-step one_step_model\n",
        "  result.append(next_char) # Menambahkan nilai next_char ke list result\n",
        "\n",
        "print(tf.strings.join(result)[0].numpy().decode(\"utf-8\")) # # menggabungkan semua elemen dari list result menjadi satu string dan menampilkan hasilnya dalam format decode utf-8"
      ],
      "metadata": {
        "id": "ymyP134vNnXU",
        "outputId": "6539acab-df7f-49ed-b0b1-c2bb5c2910b0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ROMEO:\n",
            "The friend aforements the old man of time past wrong'd,\n",
            "Which restrained gown to be his wife anothe\n"
          ]
        }
      ]
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}