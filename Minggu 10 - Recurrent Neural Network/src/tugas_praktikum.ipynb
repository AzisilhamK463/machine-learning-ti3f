{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bj0cdpeAOjdO"
      },
      "source": [
        "### Tugas Praktikum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "id": "36m15bXHOjdP"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import os\n",
        "import time"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Praktikum 2"
      ],
      "metadata": {
        "id": "4q50SVvOPYEU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "path_to_file = tf.keras.utils.get_file('shakespeare.txt', 'https://storage.googleapis.com/download.tensorflow.org/data/shakespeare.txt')"
      ],
      "metadata": {
        "id": "zXhOAkkIPN_s"
      },
      "execution_count": 51,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = open(path_to_file, 'rb').read().decode(encoding='utf-8')\n",
        "print(f'Length of text: {len(text)} characters')"
      ],
      "metadata": {
        "id": "j_ABkdYHPfZq",
        "outputId": "cca49d94-30aa-49bf-def4-161bb38c02d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Length of text: 1115394 characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(text[:250])"
      ],
      "metadata": {
        "id": "cE-erCeMPk_T",
        "outputId": "7cb86e50-8de4-4019-d058-ab584b9738da",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "First Citizen:\n",
            "Before we proceed any further, hear me speak.\n",
            "\n",
            "All:\n",
            "Speak, speak.\n",
            "\n",
            "First Citizen:\n",
            "You are all resolved rather to die than to famish?\n",
            "\n",
            "All:\n",
            "Resolved. resolved.\n",
            "\n",
            "First Citizen:\n",
            "First, you know Caius Marcius is chief enemy to the people.\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab = sorted(set(text))\n",
        "print(f'{len(vocab)} unique characters')"
      ],
      "metadata": {
        "id": "nYAtMOWvPnnL",
        "outputId": "cefc33d0-718f-4c06-ddc3-43194d41b246",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "65 unique characters\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "example_texts = ['abcdefg', 'xyz']\n",
        "chars = tf.strings.unicode_split(example_texts, input_encoding='UTF-8')\n",
        "chars"
      ],
      "metadata": {
        "id": "jRVVXB40PsKY",
        "outputId": "d68f0625-cee6-47f3-c1db-fccfce0d9890",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_from_chars = tf.keras.layers.StringLookup(vocabulary=list(vocab), mask_token=None)"
      ],
      "metadata": {
        "id": "qlDgQRLEPxn4"
      },
      "execution_count": 56,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ids = ids_from_chars(chars)\n",
        "ids"
      ],
      "metadata": {
        "id": "oddR0gCNP2DP",
        "outputId": "280b7276-021f-4dfe-ab30-9ec76bcb8a46",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 57,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[40, 41, 42, 43, 44, 45, 46], [63, 64, 65]]>"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chars_from_ids = tf.keras.layers.StringLookup(vocabulary=ids_from_chars.get_vocabulary(), invert=True, mask_token=None)"
      ],
      "metadata": {
        "id": "EP7OZPVjP7Is"
      },
      "execution_count": 58,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = chars_from_ids(ids)\n",
        "chars"
      ],
      "metadata": {
        "id": "6iGUlkheP_d9",
        "outputId": "eb6a6048-5fc7-4c48-c504-89f21dec1dba",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.RaggedTensor [[b'a', b'b', b'c', b'd', b'e', b'f', b'g'], [b'x', b'y', b'z']]>"
            ]
          },
          "metadata": {},
          "execution_count": 59
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.strings.reduce_join(chars, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "Qbpl6BnmQDhX",
        "outputId": "be14c4b4-b905-43d5-ea85-8b3fd4d600c8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([b'abcdefg', b'xyz'], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def text_from_ids(ids):\n",
        "    return tf.strings.reduce_join(chars_from_ids(ids), axis=-1)"
      ],
      "metadata": {
        "id": "wv5hXHjrQGF_"
      },
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "all_ids = ids_from_chars(tf.strings.unicode_split(text, 'UTF-8'))\n",
        "all_ids"
      ],
      "metadata": {
        "id": "XXS12f30QIjk",
        "outputId": "73281cbf-0ddb-43ca-d400-dbea89cd1802",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 62,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tf.Tensor: shape=(1115394,), dtype=int64, numpy=array([19, 48, 57, ..., 46,  9,  1])>"
            ]
          },
          "metadata": {},
          "execution_count": 62
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ids_dataset = tf.data.Dataset.from_tensor_slices(all_ids)"
      ],
      "metadata": {
        "id": "kF4P3EX0QM46"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for ids in ids_dataset.take(10):\n",
        "    print(chars_from_ids(ids).numpy().decode('utf-8'))"
      ],
      "metadata": {
        "id": "h367tpdXQSBV",
        "outputId": "0b4d9d66-1a06-4a47-bdbe-bd0e7834c7d1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F\n",
            "i\n",
            "r\n",
            "s\n",
            "t\n",
            " \n",
            "C\n",
            "i\n",
            "t\n",
            "i\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "seq_length = 100"
      ],
      "metadata": {
        "id": "9LkO21TwQpgi"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sequences = ids_dataset.batch(seq_length+1, drop_remainder=True)\n",
        "\n",
        "for seq in sequences.take(1):\n",
        "  print(chars_from_ids(seq))"
      ],
      "metadata": {
        "id": "_LYLSHmGQqSQ",
        "outputId": "3914f8fc-baa9-4b14-c1e9-f0873e6f8090",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 66,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tf.Tensor(\n",
            "[b'F' b'i' b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':'\n",
            " b'\\n' b'B' b'e' b'f' b'o' b'r' b'e' b' ' b'w' b'e' b' ' b'p' b'r' b'o'\n",
            " b'c' b'e' b'e' b'd' b' ' b'a' b'n' b'y' b' ' b'f' b'u' b'r' b't' b'h'\n",
            " b'e' b'r' b',' b' ' b'h' b'e' b'a' b'r' b' ' b'm' b'e' b' ' b's' b'p'\n",
            " b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'A' b'l' b'l' b':' b'\\n' b'S' b'p' b'e'\n",
            " b'a' b'k' b',' b' ' b's' b'p' b'e' b'a' b'k' b'.' b'\\n' b'\\n' b'F' b'i'\n",
            " b'r' b's' b't' b' ' b'C' b'i' b't' b'i' b'z' b'e' b'n' b':' b'\\n' b'Y'\n",
            " b'o' b'u' b' '], shape=(101,), dtype=string)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for seq in sequences.take(5):\n",
        "    print(text_from_ids(seq).numpy())"
      ],
      "metadata": {
        "id": "M778JhDRQvoJ",
        "outputId": "f596f305-b8e8-46ad-aec7-8b2511d7a417",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n",
            "b'are all resolved rather to die than to famish?\\n\\nAll:\\nResolved. resolved.\\n\\nFirst Citizen:\\nFirst, you k'\n",
            "b\"now Caius Marcius is chief enemy to the people.\\n\\nAll:\\nWe know't, we know't.\\n\\nFirst Citizen:\\nLet us ki\"\n",
            "b\"ll him, and we'll have corn at our own price.\\nIs't a verdict?\\n\\nAll:\\nNo more talking on't; let it be d\"\n",
            "b'one: away, away!\\n\\nSecond Citizen:\\nOne word, good citizens.\\n\\nFirst Citizen:\\nWe are accounted poor citi'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def split_input_target(sequence):\n",
        "    input_text = sequence[:-1]\n",
        "    target_text = sequence[1:]\n",
        "    return input_text, target_text"
      ],
      "metadata": {
        "id": "aGpuNtc9RIIP"
      },
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "split_input_target(list(\"Tensorflow\"))"
      ],
      "metadata": {
        "id": "FJ5nxu_5RLQS",
        "outputId": "4436bbee-3936-4e4c-d5d1-dd10188eff2d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(['T', 'e', 'n', 's', 'o', 'r', 'f', 'l', 'o'],\n",
              " ['e', 'n', 's', 'o', 'r', 'f', 'l', 'o', 'w'])"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset = sequences.map(split_input_target)"
      ],
      "metadata": {
        "id": "Qvj6MpiTRPAq"
      },
      "execution_count": 70,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example, target_example in dataset.take(1):\n",
        "    print(\"Input :\", text_from_ids(input_example).numpy())\n",
        "    print(\"Target:\", text_from_ids(target_example).numpy())"
      ],
      "metadata": {
        "id": "mQhD1H36RR6n",
        "outputId": "6273ab83-7f00-4ff1-96c8-5713f39967d3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input : b'First Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou'\n",
            "Target: b'irst Citizen:\\nBefore we proceed any further, hear me speak.\\n\\nAll:\\nSpeak, speak.\\n\\nFirst Citizen:\\nYou '\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "BATCH_SIZE = 64\n",
        "\n",
        "BUFFER_SIZE = 10000\n",
        "\n",
        "dataset = (\n",
        "    dataset\n",
        "    .shuffle(BUFFER_SIZE)\n",
        "    .batch(BATCH_SIZE, drop_remainder=True)\n",
        "    .prefetch(tf.data.experimental.AUTOTUNE))\n",
        "\n",
        "dataset"
      ],
      "metadata": {
        "id": "kOLL5cp-RW_6",
        "outputId": "a8aa5218-f40b-4e5a-948e-416fb817d9ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<_PrefetchDataset element_spec=(TensorSpec(shape=(64, 100), dtype=tf.int64, name=None), TensorSpec(shape=(64, 100), dtype=tf.int64, name=None))>"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "vocab_size = len(ids_from_chars.get_vocabulary())\n",
        "\n",
        "embedding_dim = 256\n",
        "\n",
        "rnn_units = 1024"
      ],
      "metadata": {
        "id": "r6dXi2hgRnMc"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MyModel(tf.keras.Model):\n",
        "  def __init__(self, vocab_size, embedding_dim, rnn_units):\n",
        "    super().__init__(self)\n",
        "    self.embedding = tf.keras.layers.Embedding(vocab_size, embedding_dim)\n",
        "    self.gru = tf.keras.layers.GRU(rnn_units,\n",
        "                                   return_sequences=True,\n",
        "                                   return_state=True)\n",
        "    self.dense = tf.keras.layers.Dense(vocab_size)\n",
        "\n",
        "  def call(self, inputs, states=None, return_state=False, training=False):\n",
        "    x = inputs\n",
        "    x = self.embedding(x, training=training)\n",
        "    if states is None:\n",
        "      states = self.gru.get_initial_state(x)\n",
        "    x, states = self.gru(x, initial_state=states, training=training)\n",
        "    x = self.dense(x, training=training)\n",
        "\n",
        "    if return_state:\n",
        "      return x, states\n",
        "    else:\n",
        "      return x"
      ],
      "metadata": {
        "id": "znhBRK3xSAMF"
      },
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = MyModel(\n",
        "    vocab_size=vocab_size,\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "yZ1owMM5SUAN"
      },
      "execution_count": 75,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for input_example_batch, target_example_batch in dataset.take(1):\n",
        "    example_batch_predictions = model(input_example_batch)\n",
        "    print(example_batch_predictions.shape, \"# (batch_size, sequence_length, vocab_size)\")"
      ],
      "metadata": {
        "id": "SSllJ7ZVSaON",
        "outputId": "e91f47c4-db0c-4cb4-cd95-f7144b150a67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(64, 100, 66) # (batch_size, sequence_length, vocab_size)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "id": "8yws1mWnSp2p",
        "outputId": "20ae02a2-7209-413c-ce09-f74ee303a4b5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 77,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"my_model_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding_1 (Embedding)     multiple                  16896     \n",
            "                                                                 \n",
            " gru_1 (GRU)                 multiple                  3938304   \n",
            "                                                                 \n",
            " dense_1 (Dense)             multiple                  67650     \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 4022850 (15.35 MB)\n",
            "Trainable params: 4022850 (15.35 MB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices = tf.random.categorical(example_batch_predictions[0], num_samples=1)\n",
        "sampled_indices = tf.squeeze(sampled_indices, axis=-1).numpy()"
      ],
      "metadata": {
        "id": "42qdbIE0SsfS"
      },
      "execution_count": 78,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sampled_indices"
      ],
      "metadata": {
        "id": "eqPg6oMXS0gr",
        "outputId": "ab76bc0c-85ad-4c7f-859b-3620f2878e80",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 79,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([26, 23, 51, 44, 54, 44, 51,  0, 38,  9, 54, 11, 30, 15, 14,  7, 63,\n",
              "       13,  8, 50, 49,  3, 11, 31, 43, 52, 45,  3, 12, 53, 42,  2, 53, 41,\n",
              "       38,  1, 51,  5,  4, 20, 30, 64, 60,  3, 33, 23, 43, 55, 32, 34, 14,\n",
              "       56, 31, 60, 53, 15,  1, 28, 14, 36, 34, 13, 25, 56, 56, 50, 36, 16,\n",
              "       42, 31, 49, 23, 51, 46, 56, 57, 10, 51, 53, 50, 33,  8,  7, 10, 46,\n",
              "       18,  8, 40, 23, 63, 48, 17, 38,  1, 64, 60, 39,  3, 37,  1])"
            ]
          },
          "metadata": {},
          "execution_count": 79
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Input:\\n\", text_from_ids(input_example_batch[0]).numpy())\n",
        "print()\n",
        "print(\"Next Char Predictions:\\n\", text_from_ids(sampled_indices).numpy())"
      ],
      "metadata": {
        "id": "VTtyL2hlS3M1",
        "outputId": "d87f4e10-5664-408a-d665-9b61dc466747",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 80,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Input:\n",
            " b'nap.\\nBut did I never speak of all that time?\\n\\nFirst Servant:\\nO, yes, my lord, but very idle words:\\nF'\n",
            "\n",
            "Next Char Predictions:\n",
            " b'MJleoel[UNK]Y.o:QBA,x?-kj!:Rdmf!;nc nbY\\nl&$GQyu!TJdpSUAqRunB\\nOAWU?LqqkWCcRjJlgqr3lnkT-,3gE-aJxiDY\\nyuZ!X\\n'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "loss = tf.losses.SparseCategoricalCrossentropy(from_logits=True)"
      ],
      "metadata": {
        "id": "R33ff4W8S7mS"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "example_batch_mean_loss = loss(target_example_batch, example_batch_predictions)\n",
        "print(\"Prediction shape: \", example_batch_predictions.shape, \" # (batch_size, sequence_length, vocab_size)\")\n",
        "print(\"Mean loss:        \", example_batch_mean_loss)"
      ],
      "metadata": {
        "id": "2U0m-kLxS-XD",
        "outputId": "e9c6e005-453c-4180-ab07-36e3979790ac",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Prediction shape:  (64, 100, 66)  # (batch_size, sequence_length, vocab_size)\n",
            "Mean loss:         tf.Tensor(4.1905575, shape=(), dtype=float32)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tf.exp(example_batch_mean_loss).numpy()"
      ],
      "metadata": {
        "id": "lcUxTrEdS-gu",
        "outputId": "fe16c1a9-9569-4b97-d961-9f67935e795f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "66.05961"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss=loss)"
      ],
      "metadata": {
        "id": "pl90z7oATNYR"
      },
      "execution_count": 84,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_dir = './training_checkpoints'\n",
        "\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\n",
        "\n",
        "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
        "    filepath=checkpoint_prefix,\n",
        "    save_weights_only=True)"
      ],
      "metadata": {
        "id": "QPnP1pJrTRAx"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "history = model.fit(dataset, epochs=EPOCHS, callbacks=[checkpoint_callback])"
      ],
      "metadata": {
        "id": "rhFmGArfTWlF",
        "outputId": "f236c3ea-4b01-434b-86e0-54cbad2bab29",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "172/172 [==============================] - 14s 60ms/step - loss: 2.6791\n",
            "Epoch 2/20\n",
            "172/172 [==============================] - 15s 62ms/step - loss: 1.9517\n",
            "Epoch 3/20\n",
            "172/172 [==============================] - 14s 62ms/step - loss: 1.6752\n",
            "Epoch 4/20\n",
            "172/172 [==============================] - 13s 61ms/step - loss: 1.5210\n",
            "Epoch 5/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 1.4285\n",
            "Epoch 6/20\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 1.3641\n",
            "Epoch 7/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.3127\n",
            "Epoch 8/20\n",
            "172/172 [==============================] - 11s 57ms/step - loss: 1.2691\n",
            "Epoch 9/20\n",
            "172/172 [==============================] - 14s 61ms/step - loss: 1.2287\n",
            "Epoch 10/20\n",
            "172/172 [==============================] - 12s 63ms/step - loss: 1.1882\n",
            "Epoch 11/20\n",
            "172/172 [==============================] - 12s 59ms/step - loss: 1.1468\n",
            "Epoch 12/20\n",
            "172/172 [==============================] - 13s 60ms/step - loss: 1.1042\n",
            "Epoch 13/20\n",
            "172/172 [==============================] - 13s 63ms/step - loss: 1.0596\n",
            "Epoch 14/20\n",
            "172/172 [==============================] - 13s 57ms/step - loss: 1.0135\n",
            "Epoch 15/20\n",
            "172/172 [==============================] - 12s 62ms/step - loss: 0.9619\n",
            "Epoch 16/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.9117\n",
            "Epoch 17/20\n",
            "172/172 [==============================] - 12s 60ms/step - loss: 0.8597\n",
            "Epoch 18/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.8082\n",
            "Epoch 19/20\n",
            "172/172 [==============================] - 12s 58ms/step - loss: 0.7589\n",
            "Epoch 20/20\n",
            "172/172 [==============================] - 11s 58ms/step - loss: 0.7131\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Praktikum Tugas"
      ],
      "metadata": {
        "id": "_FOS3B7NTbo9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class CustomTraining(MyModel):\n",
        "  @tf.function\n",
        "  def train_step(self, inputs):\n",
        "      inputs, labels = inputs\n",
        "      with tf.GradientTape() as tape:\n",
        "          predictions = self(inputs, training=True)\n",
        "          loss = self.loss(labels, predictions)\n",
        "\n",
        "      grads = tape.gradient(loss, model.trainable_variables)\n",
        "      self.optimizer.apply_gradients(zip(grads, model.trainable_variables))\n",
        "\n",
        "      return {'loss': loss}"
      ],
      "metadata": {
        "id": "9BD91dXLTaNL"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = CustomTraining(\n",
        "    vocab_size=len(ids_from_chars.get_vocabulary()),\n",
        "    embedding_dim=embedding_dim,\n",
        "    rnn_units=rnn_units)"
      ],
      "metadata": {
        "id": "lDKBYbilT2JT"
      },
      "execution_count": 89,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer = tf.keras.optimizers.Adam(),\n",
        "                loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True))"
      ],
      "metadata": {
        "id": "fgjrhnvLT8R_"
      },
      "execution_count": 90,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(dataset, epochs=1)"
      ],
      "metadata": {
        "id": "0YKR2dGMUBNe",
        "outputId": "2c1e5e8d-755b-4184-9328-1f05f40d8e51",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "172/172 [==============================] - 14s 60ms/step - loss: 2.7021\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7e01b031b3a0>"
            ]
          },
          "metadata": {},
          "execution_count": 91
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "EPOCHS = 20\n",
        "\n",
        "mean = tf.metrics.Mean()\n",
        "\n",
        "for epoch in range(EPOCHS):\n",
        "    start = time.time()\n",
        "\n",
        "    mean.reset_states()\n",
        "    for (batch_n, (inp, target)) in enumerate(dataset):\n",
        "        logs = model.train_step([inp, target])\n",
        "        mean.update_state(logs['loss'])\n",
        "\n",
        "        if batch_n % 50 == 0:\n",
        "            template = f\"Epoch {epoch+1} Batch {batch_n} Loss {logs['loss']:.4f}\"\n",
        "            print(template)\n",
        "\n",
        "\n",
        "    if (epoch + 1) % 5 == 0:\n",
        "        model.save_weights(checkpoint_prefix.format(epoch=epoch))\n",
        "\n",
        "    print()\n",
        "    print(f'Epoch {epoch+1} Loss: {mean.result().numpy():.4f}')\n",
        "    print(f'Time taken for 1 epoch {time.time() - start:.2f} sec')\n",
        "    print(\"_\"*80)\n",
        "\n",
        "model.save_weights(checkpoint_prefix.format(epoch=epoch))"
      ],
      "metadata": {
        "id": "GQa_cSSbUEv0",
        "outputId": "f99ed1d2-a294-4668-c49e-c30abc8f38b1",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1 Batch 0 Loss 2.1773\n",
            "Epoch 1 Batch 50 Loss 2.0755\n",
            "Epoch 1 Batch 100 Loss 1.9566\n",
            "Epoch 1 Batch 150 Loss 1.8710\n",
            "\n",
            "Epoch 1 Loss: 1.9753\n",
            "Time taken for 1 epoch 12.76 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 2 Batch 0 Loss 1.8026\n",
            "Epoch 2 Batch 50 Loss 1.7646\n",
            "Epoch 2 Batch 100 Loss 1.6850\n",
            "Epoch 2 Batch 150 Loss 1.6484\n",
            "\n",
            "Epoch 2 Loss: 1.6997\n",
            "Time taken for 1 epoch 11.35 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 3 Batch 0 Loss 1.5591\n",
            "Epoch 3 Batch 50 Loss 1.5372\n",
            "Epoch 3 Batch 100 Loss 1.5203\n",
            "Epoch 3 Batch 150 Loss 1.4999\n",
            "\n",
            "Epoch 3 Loss: 1.5412\n",
            "Time taken for 1 epoch 11.19 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 4 Batch 0 Loss 1.4586\n",
            "Epoch 4 Batch 50 Loss 1.4690\n",
            "Epoch 4 Batch 100 Loss 1.4225\n",
            "Epoch 4 Batch 150 Loss 1.4232\n",
            "\n",
            "Epoch 4 Loss: 1.4431\n",
            "Time taken for 1 epoch 11.05 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 5 Batch 0 Loss 1.3753\n",
            "Epoch 5 Batch 50 Loss 1.3290\n",
            "Epoch 5 Batch 100 Loss 1.3759\n",
            "Epoch 5 Batch 150 Loss 1.4016\n",
            "\n",
            "Epoch 5 Loss: 1.3768\n",
            "Time taken for 1 epoch 20.59 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 6 Batch 0 Loss 1.3219\n",
            "Epoch 6 Batch 50 Loss 1.3417\n",
            "Epoch 6 Batch 100 Loss 1.3154\n",
            "Epoch 6 Batch 150 Loss 1.3364\n",
            "\n",
            "Epoch 6 Loss: 1.3249\n",
            "Time taken for 1 epoch 10.93 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 7 Batch 0 Loss 1.2543\n",
            "Epoch 7 Batch 50 Loss 1.2619\n",
            "Epoch 7 Batch 100 Loss 1.2810\n",
            "Epoch 7 Batch 150 Loss 1.2923\n",
            "\n",
            "Epoch 7 Loss: 1.2786\n",
            "Time taken for 1 epoch 11.06 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 8 Batch 0 Loss 1.2273\n",
            "Epoch 8 Batch 50 Loss 1.2542\n",
            "Epoch 8 Batch 100 Loss 1.2095\n",
            "Epoch 8 Batch 150 Loss 1.2294\n",
            "\n",
            "Epoch 8 Loss: 1.2372\n",
            "Time taken for 1 epoch 11.28 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 9 Batch 0 Loss 1.2152\n",
            "Epoch 9 Batch 50 Loss 1.2350\n",
            "Epoch 9 Batch 100 Loss 1.1857\n",
            "Epoch 9 Batch 150 Loss 1.2060\n",
            "\n",
            "Epoch 9 Loss: 1.1971\n",
            "Time taken for 1 epoch 11.39 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 10 Batch 0 Loss 1.1475\n",
            "Epoch 10 Batch 50 Loss 1.1680\n",
            "Epoch 10 Batch 100 Loss 1.1685\n",
            "Epoch 10 Batch 150 Loss 1.2067\n",
            "\n",
            "Epoch 10 Loss: 1.1571\n",
            "Time taken for 1 epoch 11.22 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 11 Batch 0 Loss 1.0932\n",
            "Epoch 11 Batch 50 Loss 1.0747\n",
            "Epoch 11 Batch 100 Loss 1.1284\n",
            "Epoch 11 Batch 150 Loss 1.1240\n",
            "\n",
            "Epoch 11 Loss: 1.1152\n",
            "Time taken for 1 epoch 10.99 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 12 Batch 0 Loss 1.0576\n",
            "Epoch 12 Batch 50 Loss 1.0828\n",
            "Epoch 12 Batch 100 Loss 1.0535\n",
            "Epoch 12 Batch 150 Loss 1.1313\n",
            "\n",
            "Epoch 12 Loss: 1.0707\n",
            "Time taken for 1 epoch 10.91 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 13 Batch 0 Loss 0.9998\n",
            "Epoch 13 Batch 50 Loss 1.0280\n",
            "Epoch 13 Batch 100 Loss 1.0460\n",
            "Epoch 13 Batch 150 Loss 1.0578\n",
            "\n",
            "Epoch 13 Loss: 1.0235\n",
            "Time taken for 1 epoch 20.47 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 14 Batch 0 Loss 0.9551\n",
            "Epoch 14 Batch 50 Loss 0.9370\n",
            "Epoch 14 Batch 100 Loss 0.9760\n",
            "Epoch 14 Batch 150 Loss 0.9882\n",
            "\n",
            "Epoch 14 Loss: 0.9747\n",
            "Time taken for 1 epoch 11.80 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 15 Batch 0 Loss 0.9041\n",
            "Epoch 15 Batch 50 Loss 0.9218\n",
            "Epoch 15 Batch 100 Loss 0.9061\n",
            "Epoch 15 Batch 150 Loss 0.9548\n",
            "\n",
            "Epoch 15 Loss: 0.9229\n",
            "Time taken for 1 epoch 11.65 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 16 Batch 0 Loss 0.8217\n",
            "Epoch 16 Batch 50 Loss 0.8486\n",
            "Epoch 16 Batch 100 Loss 0.9062\n",
            "Epoch 16 Batch 150 Loss 0.9075\n",
            "\n",
            "Epoch 16 Loss: 0.8700\n",
            "Time taken for 1 epoch 11.36 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 17 Batch 0 Loss 0.7650\n",
            "Epoch 17 Batch 50 Loss 0.7818\n",
            "Epoch 17 Batch 100 Loss 0.8347\n",
            "Epoch 17 Batch 150 Loss 0.8499\n",
            "\n",
            "Epoch 17 Loss: 0.8183\n",
            "Time taken for 1 epoch 11.32 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 18 Batch 0 Loss 0.7229\n",
            "Epoch 18 Batch 50 Loss 0.7663\n",
            "Epoch 18 Batch 100 Loss 0.8081\n",
            "Epoch 18 Batch 150 Loss 0.8015\n",
            "\n",
            "Epoch 18 Loss: 0.7668\n",
            "Time taken for 1 epoch 11.13 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 19 Batch 0 Loss 0.6458\n",
            "Epoch 19 Batch 50 Loss 0.6949\n",
            "Epoch 19 Batch 100 Loss 0.7431\n",
            "Epoch 19 Batch 150 Loss 0.7676\n",
            "\n",
            "Epoch 19 Loss: 0.7200\n",
            "Time taken for 1 epoch 11.00 sec\n",
            "________________________________________________________________________________\n",
            "Epoch 20 Batch 0 Loss 0.6503\n",
            "Epoch 20 Batch 50 Loss 0.6622\n",
            "Epoch 20 Batch 100 Loss 0.7025\n",
            "Epoch 20 Batch 150 Loss 0.7032\n",
            "\n",
            "Epoch 20 Loss: 0.6757\n",
            "Time taken for 1 epoch 10.94 sec\n",
            "________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- Jalankan kode diatas dan sebutkan perbedaanya dengan praktikum 2?\n",
        "\n",
        "> Praktikum 2 memiliki estimasi waktu yang lebih cepat untuk menjalankan proses setiap epoch daripada Praktikum Tugas. Ini karena, meskipun estimasi waktu Praktikum Tugas tetap sama, yaitu 11 hingga 14 detik, estimasi Praktikum Tugas melonjak menjadi 20.59 detik pada epoch 5.\n",
        "\n",
        "> Namun, nilai kehilangan yang dihasilkan pada Praktikum Tugas lebih rendah daripada pada Praktikum 2. Nilai kehilangan pada Epoch 1 Praktikum 2 adalah 2.6791 dan Epoch 20 menghasilkan nilai kehilangan 0.7131, sedangkan pada Epoch Praktikum Tugas dimulai dengan nilai kehilangan 2.0049 pada Epoch 1 dan berakhir dengan nilai kehilangan 0.7067 pada Epoch 20."
      ],
      "metadata": {
        "id": "MpP0lB_GUkdG"
      }
    }
  ],
  "metadata": {
    "language_info": {
      "name": "python"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU",
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}